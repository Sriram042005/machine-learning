# -*- coding: utf-8 -*-
"""sms_spam_predic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LODoQVO3p-u8Y_UlXcUkmDLPkFQsY3qB
"""

import tensorflow as tf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout

# --- 2. Load and Preprocess Data ---
print("Loading and preprocessing data...")

try:
    df = pd.read_csv('spam.csv', encoding='latin-1')
except FileNotFoundError:
    print("Error: 'spam.csv' not found. Please upload it to your Colab session.")
    # Exit the script if the file isn't there
    exit()

# Clean up the dataframe
df = df[['v1', 'v2']]
df.columns = ['label', 'message']
df['label'] = df['label'].map({'ham': 0, 'spam': 1}) # Convert labels to 0 and 1

# Get messages and labels
messages = df['message'].values
labels = df['label'].values

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(messages, labels, test_size=0.2, random_state=42)    #0.2 = 20 percent of testing data

# --- 3. Tokenize and Pad Text ---
print("Tokenizing and padding text data...")
# Parameters for tokenization and padding
vocab_size = 5000   # Max number of words to keep
max_length = 100    # Max length of sequences
embedding_dim = 16  # Dimension of the embedding vector

# Create a tokenizer and fit it on the training data
tokenizer = Tokenizer(num_words=vocab_size, oov_token="<OOV>") # <OOV> for out-of-vocabulary words
tokenizer.fit_on_texts(X_train)

# Convert texts to sequences of integers
X_train_sequences = tokenizer.texts_to_sequences(X_train)
X_test_sequences = tokenizer.texts_to_sequences(X_test)

# Pad sequences to ensure they all have the same length
X_train_padded = pad_sequences(X_train_sequences, maxlen=max_length, padding='post', truncating='post')
X_test_padded = pad_sequences(X_test_sequences, maxlen=max_length, padding='post', truncating='post')

print(f"Shape of padded training data: {X_train_padded.shape}")
print(f"Shape of padded test data: {X_test_padded.shape}")


# --- 4. Build the RNN Model ---
print("\nBuilding the RNN model...")
model = Sequential([
    # 1. Embedding layer
    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),

    # 2. LSTM layer
    LSTM(32), # 32 units in the LSTM cell

    # 3. Optional Dropout for regularization
    Dropout(0.5),

    # 4. Dense output layer for binary classification
    Dense(1, activation='sigmoid')
])

# Display model architecture
model.summary()


# --- 5. Compile the Model ---
print("\nCompiling the model...")
model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])


# --- 6. Train the Model ---
print("\nTraining the model...")
num_epochs = 15
history = model.fit(X_train_padded, y_train,
                    epochs=num_epochs,
                    validation_data=(X_test_padded, y_test),
                    verbose=2)


# --- 7. Evaluate and Plot Results ---
print("\nEvaluating the model...")
loss, accuracy = model.evaluate(X_test_padded, y_test)
print(f"\nTest Accuracy: {accuracy * 100:.2f}%")

# Plotting function
def plot_graphs(history, string):
    plt.plot(history.history[string])
    plt.plot(history.history['val_'+string])
    plt.xlabel("Epochs")
    plt.ylabel(string)
    plt.legend(['train', 'validation'], loc='upper left')
    plt.title(f'Training and Validation {string.capitalize()}')
    plt.show()

# Plot accuracy and loss
plot_graphs(history, "accuracy")
plot_graphs(history, "loss")


# --- 8. Make a Prediction on a New Message ---
print("\nMaking predictions on new messages...")
new_messages = [
    "Congratulations! You've won a $1,000 Walmart gift card. Go to http://bit.ly/12345 to claim now.",
    "Hey, are we still on for lunch tomorrow at 1pm? Let me know.",
    "URGENT! Your account has been suspended. Please verify your details here to avoid closure."
]

# Preprocess the new messages
new_sequences = tokenizer.texts_to_sequences(new_messages)
new_padded = pad_sequences(new_sequences, maxlen=max_length, padding='post', truncating='post')

# Get predictions
predictions = model.predict(new_padded)

# Interpret predictions
for i, pred in enumerate(predictions):
    sentiment = "Spam" if pred > 0.5 else "Not Spam (Ham)"
    print(f"Message: '{new_messages[i]}'")
    print(f"Prediction: {sentiment} (Confidence: {pred[0]:.2f})\n")